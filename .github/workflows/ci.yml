name: CI

env:
  CACHE_VERSION: v1

on:
  push:
    branches:
      - main
  workflow_call:

jobs:
  staleness-guard:
    name: Guard latest main commit
    runs-on: ubuntu-latest
    outputs:
      skip: ${{ steps.stale-check.outputs.skip }}
    steps:
      - uses: actions/checkout@v4
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        with:
          fetch-depth: 0
      - name: Detect stale main push
        id: stale-check
        run: |
          if [ "${GITHUB_EVENT_NAME}" != "push" ] || [ "${GITHUB_REF}" != "refs/heads/main" ]; then
            echo "skip=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          git fetch origin main --depth=1
          latest="$(git rev-parse origin/main)"
          current="$(git rev-parse HEAD)"

          if [ "${latest}" != "${current}" ]; then
            echo "Detected newer main commit ${latest}; skipping checks for ${current}."
            echo "skip=true" >> "$GITHUB_OUTPUT"
          else
            echo "skip=false" >> "$GITHUB_OUTPUT"
          fi

  bootstrap:
    name: Bootstrap CI metrics
    needs: staleness-guard
    if: needs.staleness-guard.outputs.skip != 'true'
    runs-on: ubuntu-latest
    outputs:
      started-at: ${{ steps.start.outputs.started_at }}
    steps:
      - name: Capture workflow start
        id: start
        run: echo "started_at=$(date +%s)" >> "$GITHUB_OUTPUT"

  python:
    name: Python 3.11 checks
    needs: bootstrap
    if: needs.bootstrap.result == 'success'
    runs-on: ubuntu-latest
    permissions:
      contents: read
    strategy:
      matrix:
        check: [ruff, mypy, pytest]
    steps:
      - name: Capture job start
        run: echo "PY_JOB_START=$(date +%s)" >> "$GITHUB_ENV"
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Compute dependency hashes
        id: lock-hash
        run: >-
          python scripts/cache/hash_lockfiles.py --python requirements.txt --node upstream/chainlit/pnpm-lock.yaml --node upstream/chainlit/frontend/pnpm-lock.yaml
      - name: Cache pip dependencies
        id: cache-python
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: >-
            python-${{ env.CACHE_VERSION }}-${{ runner.os }}-py311-${{ matrix.check }}-${{ steps.lock-hash.outputs.python-hash }}
          restore-keys: |
            python-${{ env.CACHE_VERSION }}-${{ runner.os }}-py311-${{ matrix.check }}-
            python-${{ env.CACHE_VERSION }}-${{ runner.os }}-
      - name: Cache pnpm store (optional)
        if: steps.lock-hash.outputs.node-hash != ''
        id: cache-node
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: >-
            node-${{ env.CACHE_VERSION }}-${{ runner.os }}-${{ steps.lock-hash.outputs.node-hash }}
          restore-keys: |
            node-${{ env.CACHE_VERSION }}-${{ runner.os }}-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt
          case "${{ matrix.check }}" in
            ruff) python -m pip install ruff ;;
            mypy) python -m pip install mypy ;;
            pytest) python -m pip install pytest ;; 
          esac
      - name: Run ${{ matrix.check }}
        run: |
          case "${{ matrix.check }}" in
            ruff) ruff check . ;;
            mypy) mypy --strict ;;
            pytest) pytest -q ;;
          esac
      - name: Summarize python job metrics
        if: always()
        run: |
          end_ts=$(date +%s)
          duration=$((end_ts - PY_JOB_START))
          hit_python="${{ steps.cache-python.outputs.cache-hit }}"
          hit_node="${{ steps.cache-node.outputs.cache-hit || 'false' }}"
          {
            echo "### Python ${{ matrix.check }} job metrics"
            echo ""
            echo "- Cache version: ${CACHE_VERSION}"
            echo "- Pip cache hit: ${hit_python:-false}"
            echo "- pnpm cache hit: ${hit_node}"
            echo "- Duration (s): ${duration}"
          } >> "$GITHUB_STEP_SUMMARY"

  node:
    name: Node 20 checks
    needs: staleness-guard
    if: needs.staleness-guard.outputs.skip != 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: read
    strategy:
      matrix:
        check: [lint, test]
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
        with:
          version: 9.15.9
      - uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "pnpm"
          cache-dependency-path: upstream/chainlit/pnpm-lock.yaml
      - name: Install dependencies
        working-directory: upstream/chainlit
        run: pnpm install --frozen-lockfile
      - name: Run pnpm ${{ matrix.check }}
        working-directory: upstream/chainlit
        run: pnpm ${{ matrix.check }}

  provider-integration:
    name: Provider smoke tests
    runs-on: ubuntu-latest
    needs:
      - python
      - node
    if: needs.python.result == 'success' && needs.node.result == 'success'
    permissions:
      contents: read
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      GOOGLE_GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
    steps:
      - name: Check provider secrets
        id: check-secrets
        run: |
          if [ -z "${OPENAI_API_KEY:-}" ] || [ -z "${GEMINI_API_KEY:-}" ]; then
            echo "Provider secrets not configured; skipping smoke tests."
            echo "ready=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          echo "ready=true" >> "$GITHUB_OUTPUT"
      - name: Capture job start
        if: steps.check-secrets.outputs.ready == 'true'
        run: echo "PROVIDER_JOB_START=$(date +%s)" >> "$GITHUB_ENV"
      - uses: actions/checkout@v4
        if: steps.check-secrets.outputs.ready == 'true'
      - uses: actions/setup-python@v5
        if: steps.check-secrets.outputs.ready == 'true'
        with:
          python-version: "3.11"
      - name: Compute dependency hashes
        id: provider-lock-hash
        if: steps.check-secrets.outputs.ready == 'true'
        run: >-
          python scripts/cache/hash_lockfiles.py --python requirements.txt --node upstream/chainlit/pnpm-lock.yaml --node upstream/chainlit/frontend/pnpm-lock.yaml
      - name: Cache pip dependencies
        id: provider-cache-python
        if: steps.check-secrets.outputs.ready == 'true'
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: >-
            provider-${{ env.CACHE_VERSION }}-${{ runner.os }}-py311-${{ steps.provider-lock-hash.outputs.python-hash }}
          restore-keys: |
            provider-${{ env.CACHE_VERSION }}-${{ runner.os }}-
      - name: Cache pnpm store (optional)
        if: steps.check-secrets.outputs.ready == 'true' && steps.provider-lock-hash.outputs.node-hash != ''
        id: provider-cache-node
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/store
          key: >-
            provider-node-${{ env.CACHE_VERSION }}-${{ runner.os }}-${{ steps.provider-lock-hash.outputs.node-hash }}
          restore-keys: |
            provider-node-${{ env.CACHE_VERSION }}-${{ runner.os }}-
      - name: Install provider dependencies
        if: steps.check-secrets.outputs.ready == 'true'
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt google-generativeai
      - name: OpenAI smoke test
        if: steps.check-secrets.outputs.ready == 'true'
        run: |
          python - <<'PY'
          from openai import OpenAI

          def extract_text(response):
              direct = getattr(response, "output_text", None)
              if direct:
                  return direct
              return "".join(
                  getattr(part, "text", "")
                  for item in getattr(response, "output", []) or []
                  for part in getattr(item, "content", []) or []
              )


          client = OpenAI()
          text = extract_text(client.responses.create(model="gpt-4o-mini", input="Respond with OK")).strip().lower()
          if "ok" not in text:
              raise SystemExit("Unexpected OpenAI response")
          PY
      - name: Gemini smoke test
        if: steps.check-secrets.outputs.ready == 'true'
        run: |
          python - <<'PY'
          import os

          import google.generativeai as genai

          api_key = os.getenv("GOOGLE_GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
          if not api_key:
              raise SystemExit("Missing Gemini API key")
          genai.configure(api_key=api_key)
          result = genai.GenerativeModel("gemini-1.5-flash").generate_content("Respond with OK")
          text = (result.text or "").strip().lower()
          if "ok" not in text:
              raise SystemExit("Unexpected Gemini response")
          PY
      - name: Summarize provider job metrics
        if: always() && steps.check-secrets.outputs.ready == 'true'
        run: |
          end_ts=$(date +%s)
          duration=$((end_ts - PROVIDER_JOB_START))
          hit_python="${{ steps.provider-cache-python.outputs.cache-hit }}"
          hit_node="${{ steps.provider-cache-node.outputs.cache-hit || 'false' }}"
          {
            echo "### Provider smoke job metrics"
            echo ""
            echo "- Cache version: ${CACHE_VERSION}"
            echo "- Pip cache hit: ${hit_python:-false}"
            echo "- pnpm cache hit: ${hit_node}"
            echo "- Duration (s): ${duration}"
          } >> "$GITHUB_STEP_SUMMARY"

  ci-metrics:
    name: CI workflow metrics
    runs-on: ubuntu-latest
    needs:
      - staleness-guard
      - bootstrap
      - python
      - provider-integration
    if: needs.staleness-guard.outputs.skip != 'true' && always()
    steps:
      - name: Summarize workflow duration
        run: |
          start_ts="${{ needs.bootstrap.outputs.started-at }}"
          end_ts=$(date +%s)
          duration=$((end_ts - start_ts))
          start_iso=$(date -u -d "@${start_ts}" '+%Y-%m-%dT%H:%M:%SZ')
          end_iso=$(date -u '+%Y-%m-%dT%H:%M:%SZ')
          echo "Workflow duration: ${duration}s"
          {
            echo "### CI workflow summary"
            echo ""
            echo "- Cache version: ${CACHE_VERSION}"
            echo "- Started (UTC): ${start_iso}"
            echo "- Finished (UTC): ${end_iso}"
            echo "- Duration (s): ${duration}"
            echo "- Python job status: ${{ needs.python.result }}"
            echo "- Provider job status: ${{ needs.provider-integration.result }}"
          } >> "$GITHUB_STEP_SUMMARY"
